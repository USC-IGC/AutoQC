{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "import skopt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "%precision 4\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_list = [\"temporalpole\", \"frontalpole\", \"bankssts\", \"superiortemporal\", \"middletemporal\", \n",
    "               \"precentral\", \"postcentral\", \"supramarginal\", \"superiorparietal\", \"precuneus\", \"cuneus\", \n",
    "               \"pericalcarine\", \"lingual\", \"superiorfrontal\", \"rostralanteriorcingulate\", \"caudalanteriorcingulate\",\n",
    "               \"posteriorcingulate\", \"isthmuscingulate\", \"medialorbitofrontal\", \"inferiortemporal\", \"lateraloccipital\",\n",
    "               \"inferiorparietal\", \"caudalmiddlefrontal\", \"rostralmiddlefrontal\", \"lateralorbitofrontal\",\n",
    "               \"parsorbitalis\", \"parstriangularis\", \"parsopercularis\", \"insula\", \"transversetemporal\", \"entorhinal\",\n",
    "               \"paracentral\", \"fusiform\", \"parahippocampal\"]\n",
    "\n",
    "\n",
    "prec_ukbb = []\n",
    "rec_ukbb = []\n",
    "acc_ukbb = []\n",
    "balacc_ukbb = []\n",
    "f1_ukbb = []\n",
    "spec_ukbb = []\n",
    "\n",
    "prec_pnc = []\n",
    "rec_pnc = []\n",
    "acc_pnc = []\n",
    "balacc_pnc = []\n",
    "f1_pnc = []\n",
    "spec_pnc = []\n",
    "\n",
    "prec_ppmi = []\n",
    "rec_ppmi = []\n",
    "acc_ppmi = []\n",
    "balacc_ppmi = []\n",
    "f1_ppmi = []\n",
    "spec_ppmi = []\n",
    "\n",
    "prec_adni = []\n",
    "rec_adni = []\n",
    "acc_adni = []\n",
    "balacc_adni = []\n",
    "f1_adni = []\n",
    "spec_adni = []\n",
    "    \n",
    "df_metric_ukbb = pd.DataFrame()\n",
    "df_metric_pnc = pd.DataFrame()\n",
    "df_metric_ppmi = pd.DataFrame()\n",
    "df_metric_adni = pd.DataFrame()\n",
    "\n",
    "df_prediction_adni = pd.DataFrame()\n",
    "df_prediction_ppmi = pd.DataFrame()\n",
    "df_prediction_pnc = pd.DataFrame()\n",
    "df_prediction_ukbb = pd.DataFrame()\n",
    "\n",
    "df_metric_ukbb[\"ROI\"] = roi_list\n",
    "df_metric_pnc[\"ROI\"] = roi_list\n",
    "df_metric_ppmi[\"ROI\"] = roi_list\n",
    "df_metric_adni[\"ROI\"] = roi_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(search_params):\n",
    "    X_trn, X_valid, y_trn, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=1234)\n",
    "\n",
    "    train_data = lgb.Dataset(X_trn, label=y_trn)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "\n",
    "    params = {'objective': 'binary',\n",
    "              'metric': 'auc',\n",
    "              'is_unbalance': True,\n",
    "              **search_params}\n",
    "\n",
    "    model = lgb.train(params, train_data,\n",
    "                      num_boost_round=300,\n",
    "                      early_stopping_rounds=30,\n",
    "                      valid_sets=[valid_data],\n",
    "                      valid_names=['valid'])\n",
    "\n",
    "    score = model.best_score['valid']['auc']\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporalpole done\n",
      "frontalpole done\n",
      "bankssts done\n",
      "superiortemporal done\n",
      "middletemporal done\n",
      "precentral done\n",
      "postcentral done\n",
      "supramarginal done\n",
      "superiorparietal done\n",
      "precuneus done\n",
      "cuneus done\n",
      "pericalcarine done\n",
      "lingual done\n",
      "superiorfrontal done\n",
      "rostralanteriorcingulate done\n",
      "caudalanteriorcingulate done\n",
      "posteriorcingulate done\n",
      "isthmuscingulate done\n",
      "medialorbitofrontal done\n",
      "inferiortemporal done\n",
      "lateraloccipital done\n",
      "inferiorparietal done\n",
      "caudalmiddlefrontal done\n",
      "rostralmiddlefrontal done\n",
      "lateralorbitofrontal done\n",
      "parsorbitalis done\n",
      "parstriangularis done\n",
      "parsopercularis done\n",
      "insula done\n",
      "transversetemporal done\n",
      "entorhinal done\n",
      "paracentral done\n",
      "fusiform done\n",
      "parahippocampal done\n"
     ]
    }
   ],
   "source": [
    "for selected_roi in roi_list:\n",
    "    #Read data\n",
    "    df_ukbb = pd.read_csv('./UKBB_v5p3/merged.csv')\n",
    "    df_pnc = pd.read_csv('./PNC/merged.csv')\n",
    "    df_ppmi = pd.read_csv('./PPMI/merged.csv')\n",
    "    test_adni = pd.read_csv('./ADNI/merged.csv')\n",
    "\n",
    "    #Train dataset\n",
    "    df_ukbb['score'] = 0\n",
    "    df_ukbb.loc[df_ukbb[selected_roi].isin(['L', 'R', ' R', 'R/L', 'RL']), ['score']] = 1\n",
    "    \n",
    "    df_pnc['score'] = 0\n",
    "    df_pnc.loc[df_pnc[selected_roi].isin(['L', 'R', ' R', 'R/L', 'RL']), ['score']] = 1\n",
    "\n",
    "    df_ppmi['score'] = 0\n",
    "    df_ppmi.loc[df_ppmi[selected_roi].isin(['L', 'R', ' R', 'R/L', 'RL']), ['score']] = 1\n",
    "\n",
    "    #Test dataset\n",
    "    test_adni['score'] = 0\n",
    "    test_adni.loc[test_adni[selected_roi].isin(['L', 'R', ' R', 'R/L', 'RL']), ['score']] = 1\n",
    "\n",
    "    #Concatenate train datasets\n",
    "    df_ukbb = df_ukbb.drop(['NP_controls_2', 'AgeAtScan', 'site_id', 'NP_controls_1', 'CNS_controls_1', 'sex', 'YearsOfEducation', 'ISCED', 'CNS_controls_2', 'Race'], axis=1)\n",
    "    df_ukbb=df_ukbb.rename(columns={\"eid\": \"SubjID\"})\n",
    "    \n",
    "    train_ukbb, test_ukbb = train_test_split(df_ukbb, test_size = 0.3, random_state = 1)\n",
    "    train_pnc, test_pnc = train_test_split(df_pnc, test_size = 0.3, random_state = 1)\n",
    "    train_ppmi, test_ppmi = train_test_split(df_ppmi, test_size = 0.3, random_state = 1)\n",
    "    train = pd.concat([train_ukbb, train_pnc, train_ppmi])\n",
    "\n",
    "    #Split data\n",
    "    X_train = train.drop(['SubjID', 'score'], axis = 1)\n",
    "    X_test_ukbb = test_ukbb.drop([\"SubjID\", \"score\"], axis=1) \n",
    "    X_test_pnc = test_pnc.drop([\"SubjID\", \"score\"], axis=1) \n",
    "    X_test_ppmi = test_ppmi.drop([\"SubjID\", \"score\"], axis=1) \n",
    "    X_test_adni = test_adni.drop([\"SubjID\", \"score\"], axis=1)\n",
    "    \n",
    "    y_train = train['score']\n",
    "    y_test_ukbb = test_ukbb['score']\n",
    "    y_test_pnc = test_pnc['score']\n",
    "    y_test_ppmi = test_ppmi['score']\n",
    "    y_test_adni = test_adni['score']\n",
    "    \n",
    "    #Save the test subject id's in prediction sheet\n",
    "    df_prediction_ukbb[\"SubjID\"] = test_ukbb[\"SubjID\"]\n",
    "    df_prediction_pnc[\"SubjID\"] = test_pnc[\"SubjID\"]\n",
    "    df_prediction_ppmi[\"SubjID\"] = test_ppmi[\"SubjID\"]\n",
    "    df_prediction_adni[\"SubjID\"] = test_adni[\"SubjID\"]\n",
    "\n",
    "    #Selected columns in dataframe\n",
    "    columns = list(pd.read_csv('./features.csv').Features)\n",
    "    X_train = X_train[columns]\n",
    "    X_test_ukbb = X_test_ukbb[columns]\n",
    "    X_test_pnc = X_test_pnc[columns]\n",
    "    X_test_ppmi = X_test_ppmi[columns]\n",
    "    X_test_adni = X_test_adni[columns]\n",
    "\n",
    "    #Impute\n",
    "    X_train = SimpleImputer().fit(X_train).transform(X_train)\n",
    "    X_test_ukbb = SimpleImputer().fit(X_test_ukbb).transform(X_test_ukbb)\n",
    "    X_test_pnc = SimpleImputer().fit(X_test_pnc).transform(X_test_pnc)\n",
    "    X_test_ppmi = SimpleImputer().fit(X_test_ppmi).transform(X_test_ppmi)\n",
    "    X_test_adni = SimpleImputer().fit(X_test_adni).transform(X_test_adni)\n",
    "\n",
    "    #Normalize\n",
    "    X_train = normalize(X_train)\n",
    "    X_test_ukbb = normalize(X_test_ukbb)\n",
    "    X_test_pnc = normalize(X_test_pnc)\n",
    "    X_test_ppmi = normalize(X_test_ppmi)\n",
    "    X_test_adni = normalize(X_test_adni)\n",
    "\n",
    "    #Scaling\n",
    "    minmax = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "    filename = './models/minimax.sav'\n",
    "    pickle.dump(minmax, open(filename, 'wb'))\n",
    "    \n",
    "    X_train = minmax.transform(X_train)\n",
    "    X_test_ukbb = minmax.transform(X_test_ukbb)\n",
    "    X_test_pnc = minmax.transform(X_test_pnc)\n",
    "    X_test_ppmi = minmax.transform(X_test_ppmi)\n",
    "    X_test_adni = minmax.transform(X_test_adni)\n",
    "\n",
    "    #Generate dataframe\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_train.columns = columns\n",
    "\n",
    "    X_test_ukbb = pd.DataFrame(X_test_ukbb)\n",
    "    X_test_ukbb.columns = columns\n",
    "\n",
    "    X_test_pnc = pd.DataFrame(X_test_pnc)\n",
    "    X_test_pnc.columns = columns\n",
    "\n",
    "    X_test_ppmi = pd.DataFrame(X_test_ppmi)\n",
    "    X_test_ppmi.columns = columns\n",
    "\n",
    "    X_test_adni = pd.DataFrame(X_test_adni)\n",
    "    X_test_adni.columns = columns\n",
    "\n",
    "    # Search for best model parameters\n",
    "    SEARCH_PARAMS = {'learning_rate': 0.1,\n",
    "                 'max_depth': 1,\n",
    "                 'num_leaves': 7,\n",
    "                 'feature_fraction': 0.6, ##### feature_fraction = bagging_fraction\n",
    "                 'subsample': 0.2}\n",
    "    \n",
    "    SPACE = [\n",
    "        skopt.space.Real(0.0001, 0.5, name='learning_rate', prior='log-uniform'),\n",
    "        skopt.space.Integer(10, 50, name='max_depth'),\n",
    "        skopt.space.Integer(50, 150, name='num_leaves'),\n",
    "        skopt.space.Real(0.1, 1.0, name='feature_fraction', prior='uniform'),\n",
    "        skopt.space.Real(0.1, 1.0, name='subsample', prior='uniform')\n",
    "    ]\n",
    "\n",
    "    @skopt.utils.use_named_args(SPACE)\n",
    "    def objective(**params):\n",
    "        return -1.0 * train_evaluate(params)\n",
    "\n",
    "    results = skopt.forest_minimize(objective, SPACE, n_calls=100, base_estimator='RF')\n",
    "    best_params = results['x']\n",
    "\n",
    "    #Light Gradient Boost Classifier with random forest as the base estimator\n",
    "    clf = lgb.LGBMClassifier(boosting_type='rf', is_unbalance=True, verbose=4, objective='binary', \n",
    "                             importance_type='gain', n_estimators=100, \n",
    "                             learning_rate=best_params[0], \n",
    "                             max_depth=best_params[1], \n",
    "                             num_leaves=best_params[2], \n",
    "                             bagging_fraction = best_params[3],\n",
    "                             subsample=best_params[4],\n",
    "                             bagging_freq=1)\n",
    "    \n",
    "    filename = \"./models/model_\" + str(selected_roi) + \".sav\"\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "\n",
    "    #Training\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #Prediction on all test sets\n",
    "    y_pred_ukbb_test = clf.predict(X_test_ukbb)\n",
    "    y_pred_pnc_test = clf.predict(X_test_pnc)\n",
    "    y_pred_ppmi_test = clf.predict(X_test_ppmi)\n",
    "    y_pred_adni_test = clf.predict(X_test_adni)\n",
    "    \n",
    "    #Get confusion matrix\n",
    "    cm_ukbb = confusion_matrix(y_test_ukbb, y_pred_ukbb_test)\n",
    "    cm_pnc = confusion_matrix(y_test_pnc, y_pred_pnc_test)\n",
    "    cm_ppmi = confusion_matrix(y_test_ppmi, y_pred_ppmi_test)\n",
    "    cm_adni = confusion_matrix(y_test_adni, y_pred_adni_test)\n",
    "\n",
    "    #Store Precision, recall, accuracy, f1 score, balanced accuracy\n",
    "    prec_ukbb.append(precision_score(y_test_ukbb, y_pred_ukbb_test, average='weighted'))\n",
    "    rec_ukbb.append(recall_score(y_test_ukbb, y_pred_ukbb_test, average='weighted'))\n",
    "    acc_ukbb.append(accuracy_score(y_test_ukbb, y_pred_ukbb_test))\n",
    "    balacc_ukbb.append(balanced_accuracy_score(y_test_ukbb, y_pred_ukbb_test))\n",
    "    f1_ukbb.append(f1_score(y_test_ukbb, y_pred_ukbb_test, average='weighted'))\n",
    "    if cm_ukbb.shape == (1,1):\n",
    "        spec_ukbb.append(\"-\")\n",
    "    else:\n",
    "        spec_ukbb.append(cm_ukbb[1,1]/(cm_ukbb[1,0]+cm_ukbb[1,1]))\n",
    "\n",
    "    prec_pnc.append(precision_score(y_test_pnc, y_pred_pnc_test, average='weighted'))\n",
    "    rec_pnc.append(recall_score(y_test_pnc, y_pred_pnc_test, average='weighted'))\n",
    "    acc_pnc.append(accuracy_score(y_test_pnc, y_pred_pnc_test))\n",
    "    balacc_pnc.append(balanced_accuracy_score(y_test_pnc, y_pred_pnc_test))\n",
    "    f1_pnc.append(f1_score(y_test_pnc, y_pred_pnc_test, average='weighted'))\n",
    "    if cm_pnc.shape == (1,1):\n",
    "        spec_pnc.append(\"-\")\n",
    "    else:\n",
    "        spec_pnc.append(cm_pnc[1,1]/(cm_pnc[1,0]+cm_pnc[1,1]))\n",
    "\n",
    "    prec_ppmi.append(precision_score(y_test_ppmi, y_pred_ppmi_test, average='weighted'))\n",
    "    rec_ppmi.append(recall_score(y_test_ppmi, y_pred_ppmi_test, average='weighted'))\n",
    "    acc_ppmi.append(accuracy_score(y_test_ppmi, y_pred_ppmi_test))\n",
    "    balacc_ppmi.append(balanced_accuracy_score(y_test_ppmi, y_pred_ppmi_test))\n",
    "    f1_ppmi.append(f1_score(y_test_ppmi, y_pred_ppmi_test, average='weighted'))\n",
    "    if cm_ppmi.shape == (1,1):\n",
    "        spec_ppmi.append(\"-\")\n",
    "    else:\n",
    "        spec_ppmi.append(cm_ppmi[1,1]/(cm_ppmi[1,0]+cm_ppmi[1,1]))\n",
    "\n",
    "    prec_adni.append(precision_score(y_test_adni, y_pred_adni_test, average='weighted'))\n",
    "    rec_adni.append(recall_score(y_test_adni, y_pred_adni_test, average='weighted'))\n",
    "    acc_adni.append(accuracy_score(y_test_adni, y_pred_adni_test))\n",
    "    balacc_adni.append(balanced_accuracy_score(y_test_adni, y_pred_adni_test))\n",
    "    f1_adni.append(f1_score(y_test_adni, y_pred_adni_test, average='weighted'))\n",
    "    if cm_adni.shape == (1,1):\n",
    "        spec_adni.append(\"-\")\n",
    "    else:\n",
    "        spec_adni.append(cm_adni[1,1]/(cm_adni[1,0]+cm_adni[1,1]))\n",
    "\n",
    "    df_prediction_adni[str(selected_roi)] = y_pred_adni_test\n",
    "    df_prediction_ukbb[str(selected_roi)] = y_pred_ukbb_test\n",
    "    df_prediction_pnc[str(selected_roi)] = y_pred_pnc_test\n",
    "    df_prediction_ppmi[str(selected_roi)] = y_pred_ppmi_test\n",
    "    \n",
    "    print(selected_roi + \" done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe for all the performance metrics\n",
    "df_metric_ukbb[\"Precision\"] = prec_ukbb\n",
    "df_metric_ukbb[\"Recall\"] = rec_ukbb\n",
    "df_metric_ukbb[\"Accuracy\"] = acc_ukbb\n",
    "df_metric_ukbb[\"Balanced Accuracy\"] = balacc_ukbb\n",
    "df_metric_ukbb[\"F1\"] = f1_ukbb\n",
    "df_metric_ukbb[\"Specificity\"] = spec_ukbb\n",
    "\n",
    "df_metric_pnc[\"Precision\"] = prec_pnc\n",
    "df_metric_pnc[\"Recall\"] = rec_pnc\n",
    "df_metric_pnc[\"Accuracy\"] = acc_pnc\n",
    "df_metric_pnc[\"Balanced Accuracy\"] = balacc_pnc\n",
    "df_metric_pnc[\"F1\"] = f1_pnc\n",
    "df_metric_pnc[\"Specificity\"] = spec_pnc\n",
    "\n",
    "df_metric_ppmi[\"Precision\"] = prec_ppmi\n",
    "df_metric_ppmi[\"Recall\"] = rec_ppmi\n",
    "df_metric_ppmi[\"Accuracy\"] = acc_ppmi\n",
    "df_metric_ppmi[\"Balanced Accuracy\"] = balacc_ppmi\n",
    "df_metric_ppmi[\"F1\"] = f1_ppmi\n",
    "df_metric_ppmi[\"Specificity\"] = spec_ppmi\n",
    "\n",
    "df_metric_adni[\"Precision\"] = prec_adni\n",
    "df_metric_adni[\"Recall\"] = rec_adni\n",
    "df_metric_adni[\"Accuracy\"] = acc_adni\n",
    "df_metric_adni[\"Balanced Accuracy\"] = balacc_adni\n",
    "df_metric_adni[\"F1\"] = f1_adni\n",
    "df_metric_adni[\"Specificity\"] = spec_adni\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the performance metrics\n",
    "df_metric_ukbb.to_csv(\"./results/performance_metrics_ukbb_test.csv\")\n",
    "df_metric_ppmi.to_csv(\"./results/performance_metrics_ppmi_test.csv\")\n",
    "df_metric_pnc.to_csv(\"./results/performance_metrics_pnc_test.csv\")\n",
    "df_metric_adni.to_csv(\"./results/performance_metrics_adni_test.csv\")\n",
    "\n",
    "#Save the QC predictions\n",
    "df_prediction_ukbb.to_csv(\"./results/qc_prediction_ukbb.csv\")\n",
    "df_prediction_pnc.to_csv(\"./results/qc_prediction_pnc.csv\")\n",
    "df_prediction_ppmi.to_csv(\"./results/qc_prediction_ppmi.csv\")\n",
    "df_prediction_adni.to_csv(\"./results/qc_prediction_adni.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
